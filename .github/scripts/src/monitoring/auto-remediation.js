#!/usr/bin/env node

/**
 * Auto-Remediation Engine
 *
 * Implements self-healing runbooks for common issues:
 * 1. Queue duplicates cleanup
 * 2. Database capacity management (seen_jobs.json rotation)
 * 3. V1â†’V2 migration for legacy posts
 * 4. Rate limit backoff and recovery
 * 5. Stale jobs cleanup
 *
 * Each runbook has:
 * - Detection: Identify the issue
 * - Confidence: Score how sure we are this is the right fix
 * - Remediation: Execute the fix
 * - Validation: Verify the fix worked
 */

const fs = require('fs');
const path = require('path');

/**
 * Confidence levels for auto-remediation
 */
const CONFIDENCE = {
  HIGH: 'high',      // 90%+ confidence - auto-execute
  MEDIUM: 'medium',  // 70-90% confidence - execute with logging
  LOW: 'low'         // <70% confidence - alert only, don't execute
};

/**
 * Auto-remediation threshold
 * Only execute fixes with confidence >= MEDIUM
 */
const AUTO_EXECUTE_THRESHOLD = CONFIDENCE.MEDIUM;

/**
 * Runbook 1: Queue Duplicates Cleanup
 *
 * Detects and removes duplicate jobs from pending_posts.json
 * Confidence: HIGH (safe operation, idempotent)
 */
async function runbookQueueDuplicates() {
  const queuePath = path.join(process.cwd(), '.github', 'data', 'pending_posts.json');

  try {
    if (!fs.existsSync(queuePath)) {
      return {
        runbook: 'queue-duplicates',
        status: 'skipped',
        reason: 'No queue file found'
      };
    }

    const queue = JSON.parse(fs.readFileSync(queuePath, 'utf8'));
    const { generateJobId } = require('../../job-fetcher/utils');

    // Detect duplicates
    const seen = new Map();
    const duplicates = [];
    const unique = [];

    for (const item of queue) {
      const jobId = generateJobId(item.job);
      if (seen.has(jobId)) {
        duplicates.push({ jobId, item });
      } else {
        seen.set(jobId, true);
        unique.push(item);
      }
    }

    const duplicateCount = duplicates.length;
    const duplicateRatio = queue.length > 0 ? duplicateCount / queue.length : 0;

    // Detection
    if (duplicateCount === 0) {
      return {
        runbook: 'queue-duplicates',
        status: 'healthy',
        message: 'No duplicates detected'
      };
    }

    // Confidence calculation
    let confidence = CONFIDENCE.HIGH; // Duplicate removal is safe
    if (duplicateRatio > 0.5) {
      // Too many duplicates might indicate a deeper issue
      confidence = CONFIDENCE.MEDIUM;
    }

    // Remediation (if confidence allows)
    if (confidence === CONFIDENCE.HIGH || confidence === CONFIDENCE.MEDIUM) {
      // Backup original
      const backupPath = queuePath.replace('.json', `.backup-${Date.now()}.json`);
      fs.writeFileSync(backupPath, JSON.stringify(queue, null, 2));

      // Write cleaned queue
      fs.writeFileSync(queuePath, JSON.stringify(unique, null, 2));

      // Validation
      const cleaned = JSON.parse(fs.readFileSync(queuePath, 'utf8'));
      const success = cleaned.length === unique.length;

      return {
        runbook: 'queue-duplicates',
        status: success ? 'remediated' : 'failed',
        confidence,
        duplicates_removed: duplicateCount,
        queue_before: queue.length,
        queue_after: unique.length,
        backup: backupPath,
        message: `Removed ${duplicateCount} duplicates from queue`
      };
    } else {
      return {
        runbook: 'queue-duplicates',
        status: 'detected',
        confidence,
        duplicates_found: duplicateCount,
        message: `Found ${duplicateCount} duplicates but confidence too low to auto-remediate`
      };
    }
  } catch (error) {
    return {
      runbook: 'queue-duplicates',
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Runbook 2: Database Capacity Management
 *
 * Rotates seen_jobs.json when it exceeds size threshold
 * Confidence: MEDIUM (affects deduplication, needs careful handling)
 */
async function runbookDatabaseCapacity() {
  const seenJobsPath = path.join(process.cwd(), '.github', 'data', 'seen_jobs.json');
  const MAX_SIZE_MB = 10;
  const ROTATION_THRESHOLD = 9500; // Number of entries

  try {
    if (!fs.existsSync(seenJobsPath)) {
      return {
        runbook: 'database-capacity',
        status: 'skipped',
        reason: 'No seen_jobs.json found'
      };
    }

    const stats = fs.statSync(seenJobsPath);
    const sizeMB = stats.size / (1024 * 1024);
    const seenJobs = JSON.parse(fs.readFileSync(seenJobsPath, 'utf8'));
    const entryCount = Object.keys(seenJobs).length;

    // Detection
    if (sizeMB < MAX_SIZE_MB && entryCount < ROTATION_THRESHOLD) {
      return {
        runbook: 'database-capacity',
        status: 'healthy',
        size_mb: sizeMB.toFixed(2),
        entries: entryCount
      };
    }

    // Confidence calculation
    let confidence = CONFIDENCE.MEDIUM;
    if (entryCount > ROTATION_THRESHOLD + 500) {
      // Well over threshold, very safe to rotate
      confidence = CONFIDENCE.HIGH;
    }

    // Remediation: Archive old entries, keep recent ones
    if (confidence === CONFIDENCE.HIGH || confidence === CONFIDENCE.MEDIUM) {
      const archiveDir = path.join(process.cwd(), '.github', 'data', 'archive');
      if (!fs.existsSync(archiveDir)) {
        fs.mkdirSync(archiveDir, { recursive: true });
      }

      // Archive current file
      const timestamp = new Date().toISOString().split('T')[0];
      const archivePath = path.join(archiveDir, `seen_jobs-${timestamp}.json`);
      fs.writeFileSync(archivePath, JSON.stringify(seenJobs, null, 2));

      // Keep only recent entries (last 30 days)
      const cutoffDate = new Date(Date.now() - (30 * 24 * 60 * 60 * 1000));
      const recent = {};
      let keptCount = 0;

      for (const [key, timestamp] of Object.entries(seenJobs)) {
        const entryDate = new Date(timestamp);
        if (entryDate > cutoffDate) {
          recent[key] = timestamp;
          keptCount++;
        }
      }

      // Write rotated file
      fs.writeFileSync(seenJobsPath, JSON.stringify(recent, null, 2));

      // Validation
      const rotated = JSON.parse(fs.readFileSync(seenJobsPath, 'utf8'));
      const success = Object.keys(rotated).length === keptCount;

      return {
        runbook: 'database-capacity',
        status: success ? 'remediated' : 'failed',
        confidence,
        entries_before: entryCount,
        entries_after: keptCount,
        entries_archived: entryCount - keptCount,
        archive_path: archivePath,
        message: `Rotated seen_jobs.json: ${entryCount} â†’ ${keptCount} entries`
      };
    } else {
      return {
        runbook: 'database-capacity',
        status: 'detected',
        confidence,
        size_mb: sizeMB.toFixed(2),
        entries: entryCount,
        message: 'Database capacity issue detected but confidence too low'
      };
    }
  } catch (error) {
    return {
      runbook: 'database-capacity',
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Runbook 3: V1â†’V2 Migration
 *
 * Migrates legacy V1 posts to V2 schema
 * Confidence: LOW (complex migration, needs careful validation)
 */
async function runbookV1ToV2Migration() {
  const postedJobsPath = path.join(process.cwd(), '.github', 'data', 'posted_jobs.json');

  try {
    if (!fs.existsSync(postedJobsPath)) {
      return {
        runbook: 'v1-v2-migration',
        status: 'skipped',
        reason: 'No posted_jobs.json found'
      };
    }

    const db = JSON.parse(fs.readFileSync(postedJobsPath, 'utf8'));
    const { categorizeJobStatus } = require('../../schema-aware-health');

    // Detect V1 legacy posts
    let v1Count = 0;
    const v1Jobs = [];

    for (const job of db.jobs || []) {
      const category = categorizeJobStatus(job);
      if (category.status === 'SUCCESS' && category.schema === 'V1_LEGACY') {
        v1Count++;
        v1Jobs.push(job);
      }
    }

    // Detection
    if (v1Count === 0) {
      return {
        runbook: 'v1-v2-migration',
        status: 'healthy',
        message: 'No V1 legacy posts found'
      };
    }

    const v1Percentage = (v1Count / (db.jobs?.length || 1)) * 100;

    // Confidence calculation
    // V1â†’V2 migration is complex and risky, so we only alert
    let confidence = CONFIDENCE.LOW;

    return {
      runbook: 'v1-v2-migration',
      status: 'detected',
      confidence,
      v1_posts: v1Count,
      v1_percentage: v1Percentage.toFixed(1),
      message: `Found ${v1Count} V1 legacy posts (${v1Percentage.toFixed(1)}%). Manual migration recommended.`,
      recommendation: 'Run manual V1â†’V2 migration script to update schema'
    };
  } catch (error) {
    return {
      runbook: 'v1-v2-migration',
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Runbook 4: Rate Limit Recovery
 *
 * Detects rate limit patterns and implements backoff
 * Confidence: HIGH (safe, no data changes)
 */
async function runbookRateLimitRecovery() {
  // Check for rate limit indicators in recent logs
  const logsDir = path.join(process.cwd(), '.github', 'logs');

  try {
    // For now, return healthy (would need actual rate limit detection)
    // This is a placeholder for future implementation
    return {
      runbook: 'rate-limit-recovery',
      status: 'healthy',
      message: 'No rate limit issues detected',
      note: 'Full implementation pending - needs Discord API rate limit tracking'
    };
  } catch (error) {
    return {
      runbook: 'rate-limit-recovery',
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Runbook 5: Stale Jobs Cleanup
 *
 * Removes jobs stuck in pending state for >48 hours
 * Confidence: MEDIUM (safe, but needs validation)
 */
async function runbookStaleJobsCleanup() {
  const queuePath = path.join(process.cwd(), '.github', 'data', 'pending_posts.json');
  const STALE_THRESHOLD_HOURS = 48;

  try {
    if (!fs.existsSync(queuePath)) {
      return {
        runbook: 'stale-jobs-cleanup',
        status: 'skipped',
        reason: 'No queue file found'
      };
    }

    const queue = JSON.parse(fs.readFileSync(queuePath, 'utf8'));
    const now = Date.now();
    const staleThreshold = now - (STALE_THRESHOLD_HOURS * 60 * 60 * 1000);

    // Detect stale jobs
    const stale = [];
    const active = [];

    for (const item of queue) {
      const addedAt = new Date(item.added_at || item.timestamp || 0).getTime();
      const isPending = item.status === 'pending';
      const isStale = addedAt < staleThreshold;

      if (isPending && isStale) {
        stale.push(item);
      } else {
        active.push(item);
      }
    }

    const staleCount = stale.length;
    const staleRatio = queue.length > 0 ? staleCount / queue.length : 0;

    // Detection
    if (staleCount === 0) {
      return {
        runbook: 'stale-jobs-cleanup',
        status: 'healthy',
        message: 'No stale jobs detected'
      };
    }

    // Confidence calculation
    let confidence = CONFIDENCE.MEDIUM;
    if (staleRatio > 0.5) {
      // Too many stale jobs might indicate enrichment service down
      confidence = CONFIDENCE.LOW; // Don't auto-clean, might be temporary
    }

    // Remediation
    if (confidence === CONFIDENCE.MEDIUM) {
      // Backup original
      const backupPath = queuePath.replace('.json', `.backup-${Date.now()}.json`);
      fs.writeFileSync(backupPath, JSON.stringify(queue, null, 2));

      // Write cleaned queue
      fs.writeFileSync(queuePath, JSON.stringify(active, null, 2));

      // Validation
      const cleaned = JSON.parse(fs.readFileSync(queuePath, 'utf8'));
      const success = cleaned.length === active.length;

      return {
        runbook: 'stale-jobs-cleanup',
        status: success ? 'remediated' : 'failed',
        confidence,
        stale_jobs_removed: staleCount,
        queue_before: queue.length,
        queue_after: active.length,
        backup: backupPath,
        message: `Removed ${staleCount} stale jobs (pending >${STALE_THRESHOLD_HOURS}h)`
      };
    } else {
      return {
        runbook: 'stale-jobs-cleanup',
        status: 'detected',
        confidence,
        stale_jobs_found: staleCount,
        stale_ratio: staleRatio.toFixed(2),
        message: `Found ${staleCount} stale jobs but confidence too low (${staleRatio.toFixed(0)}% of queue)`
      };
    }
  } catch (error) {
    return {
      runbook: 'stale-jobs-cleanup',
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Run all runbooks and return results
 *
 * @returns {Promise<Object>} - Remediation results
 */
async function runAllRunbooks() {
  console.log('ðŸ”§ Running auto-remediation runbooks...\n');

  const results = {
    timestamp: new Date().toISOString(),
    runbooks: []
  };

  // Run all runbooks
  const runbooks = [
    { name: 'Queue Duplicates', fn: runbookQueueDuplicates },
    { name: 'Database Capacity', fn: runbookDatabaseCapacity },
    { name: 'V1â†’V2 Migration', fn: runbookV1ToV2Migration },
    { name: 'Rate Limit Recovery', fn: runbookRateLimitRecovery },
    { name: 'Stale Jobs Cleanup', fn: runbookStaleJobsCleanup }
  ];

  for (const { name, fn } of runbooks) {
    console.log(`ðŸ“‹ Running: ${name}...`);
    const result = await fn();
    results.runbooks.push(result);

    // Log result
    const emoji = result.status === 'remediated' ? 'âœ…' :
                  result.status === 'detected' ? 'âš ï¸' :
                  result.status === 'healthy' ? 'âœ…' :
                  result.status === 'error' ? 'âŒ' : 'â„¹ï¸';

    console.log(`${emoji} ${name}: ${result.status.toUpperCase()}`);
    if (result.message) {
      console.log(`   ${result.message}`);
    }
    console.log('');
  }

  // Summary
  const remediated = results.runbooks.filter(r => r.status === 'remediated').length;
  const detected = results.runbooks.filter(r => r.status === 'detected').length;
  const errors = results.runbooks.filter(r => r.status === 'error').length;

  console.log('â•'.repeat(50));
  console.log('ðŸ“Š Auto-Remediation Summary:');
  console.log(`   Remediated: ${remediated}`);
  console.log(`   Detected (not auto-fixed): ${detected}`);
  console.log(`   Errors: ${errors}`);
  console.log('â•'.repeat(50));

  return results;
}

// CLI usage
if (require.main === module) {
  const args = process.argv.slice(2);
  const command = args[0];

  if (command === 'run') {
    // Run all runbooks
    runAllRunbooks().then((results) => {
      console.log('\nðŸ“ Results:', JSON.stringify(results, null, 2));
      process.exit(0);
    }).catch((error) => {
      console.error('âŒ Auto-remediation failed:', error);
      process.exit(1);
    });
  } else if (command === 'test') {
    // Test individual runbook
    const runbookName = args[1];
    const runbooks = {
      'queue': runbookQueueDuplicates,
      'capacity': runbookDatabaseCapacity,
      'migration': runbookV1ToV2Migration,
      'ratelimit': runbookRateLimitRecovery,
      'stale': runbookStaleJobsCleanup
    };

    if (runbooks[runbookName]) {
      runbooks[runbookName]().then((result) => {
        console.log(JSON.stringify(result, null, 2));
      });
    } else {
      console.log('Available runbooks: queue, capacity, migration, ratelimit, stale');
    }
  } else {
    console.log(`
Auto-Remediation Engine - Self-healing runbooks for common issues

Usage:
  node auto-remediation.js run              Run all runbooks
  node auto-remediation.js test [runbook]   Test specific runbook

Runbooks:
  queue      - Remove duplicate jobs from queue
  capacity   - Rotate seen_jobs.json when too large
  migration  - Detect V1 legacy posts (alert only)
  ratelimit  - Detect and recover from rate limits
  stale      - Remove jobs stuck in pending >48h

Confidence Levels:
  HIGH   - Auto-execute (90%+ confidence)
  MEDIUM - Auto-execute with logging (70-90%)
  LOW    - Alert only, don't execute (<70%)
    `);
  }
}

module.exports = {
  runbookQueueDuplicates,
  runbookDatabaseCapacity,
  runbookV1ToV2Migration,
  runbookRateLimitRecovery,
  runbookStaleJobsCleanup,
  runAllRunbooks
};
