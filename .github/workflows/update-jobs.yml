name: Update Remote Jobs

on:
  # schedule:
  #   # DISABLED: Was running every 15 minutes (96x/day), causing quota exhaustion
  #   # RemoteOK only provides 24-48h window (~5 jobs), doesn't need frequent polling
  #   # Re-enable with hourly or 6-hourly schedule if needed: '0 */6 * * *'
  #   - cron: '*/15 * * * *'
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [ master ]
    paths:
      - '.github/scripts/job-fetcher/**'
      - '.github/scripts/unified-job-fetcher.js'
      - '.github/scripts/enhanced-discord-bot.js'
      - 'jobboard/src/backend/**'

# Prevent concurrent runs to avoid git conflicts
concurrency:
  group: job-updates-${{ github.repository }}
  cancel-in-progress: false  # Don't cancel, wait for previous to finish

jobs:
  update-jobs:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ref: master  # Always pull latest master branch code
        fetch-depth: 0  # Fetch full history for proper rebasing
        token: ${{ secrets.GITHUB_TOKEN }}  # Use default token for pushing

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: |
          package-lock.json
          jobboard/package-lock.json


    - name: Install job fetcher dependencies
      run: npm install axios

    - name: Install jobboard dependencies
      run: |
        cd jobboard
        npm install --production --no-audit --no-fund
        cd ..

    - name: Create logs directory
      run: mkdir -p .github/logs

    - name: Update job listings
      run: node .github/scripts/job-fetcher/index.js 2>&1 | tee .github/logs/job-fetcher.log
      env:
        # RemoteOK API requires no authentication or external data sources
        ENABLE_MARKDOWN_CONVERSION: true  # Feature flag: Set to 'true' to enable HTML-to-Markdown conversion

    - name: Display job-fetcher logs (always run)
      if: always()
      run: |
        echo "ðŸ“‹ Job Fetcher Output (last 100 lines):"
        tail -100 .github/logs/job-fetcher.log || echo "Log file not found"

    - name: Display public status
      run: |
        echo "âœ… Job collection completed"
        if [ -f "README.md" ]; then
          JOB_COUNT=$(grep -o "Active Positions\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          echo "ðŸ“Š Total positions: $JOB_COUNT"
        fi

    - name: Install bot dependencies
      run: npm install discord.js@14

    - name: ðŸ” BEFORE bot - Hash posted_jobs.json
      id: before-hash
      run: |
        echo "ðŸ“Š BEFORE BOT EXECUTION:"
        echo "File size: $(stat -c'%s' .github/data/posted_jobs.json 2>/dev/null || stat -f'%z' .github/data/posted_jobs.json)"
        BEFORE_HASH=$(sha256sum .github/data/posted_jobs.json 2>/dev/null | cut -d' ' -f1 || shasum -a 256 .github/data/posted_jobs.json | cut -d' ' -f1)
        echo "SHA256: $BEFORE_HASH"
        echo "hash=$BEFORE_HASH" >> $GITHUB_OUTPUT
        echo "Last 3 job IDs:"
        tail -3 .github/data/posted_jobs.json

    - name: Export jobs to encrypted JSON (for external job boards)
      run: node .github/scripts/jobs-data-exporter.js
      env:
        LOG_ENCRYPT_PASSWORD: ${{ secrets.LOG_ENCRYPT_PASSWORD }}

    - name: Post new jobs via Enhanced Bot
      run: |
        node .github/scripts/save-discord-logs.js 2>&1 | tee .github/logs/discord-bot.log
      env:
        DISCORD_TOKEN:       ${{ secrets.DISCORD_TOKEN }}
        DISCORD_CHANNEL_ID:  ${{ secrets.DISCORD_CHANNEL_ID }}
        DISCORD_CLIENT_ID:   ${{ secrets.DISCORD_CLIENT_ID }}
        DISCORD_GUILD_ID:    ${{ secrets.DISCORD_GUILD_ID }}
        # Multi-channel forum configuration
        DISCORD_TECH_CHANNEL_ID:      ${{ secrets.DISCORD_TECH_CHANNEL_ID }}
        DISCORD_AI_CHANNEL_ID:        ${{ secrets.DISCORD_AI_CHANNEL_ID }}
        DISCORD_DS_CHANNEL_ID:        ${{ secrets.DISCORD_DS_CHANNEL_ID }}
        DISCORD_SALES_CHANNEL_ID:     ${{ secrets.DISCORD_SALES_CHANNEL_ID }}
        DISCORD_MARKETING_CHANNEL_ID: ${{ secrets.DISCORD_MARKETING_CHANNEL_ID }}
        DISCORD_FINANCE_CHANNEL_ID:   ${{ secrets.DISCORD_FINANCE_CHANNEL_ID }}
        DISCORD_HEALTHCARE_CHANNEL_ID: ${{ secrets.DISCORD_HEALTHCARE_CHANNEL_ID }}
        DISCORD_PRODUCT_CHANNEL_ID:   ${{ secrets.DISCORD_PRODUCT_CHANNEL_ID }}
        DISCORD_SUPPLY_CHANNEL_ID:    ${{ secrets.DISCORD_SUPPLY_CHANNEL_ID }}
        DISCORD_PM_CHANNEL_ID:         ${{ secrets.DISCORD_PM_CHANNEL_ID }}
        DISCORD_HR_CHANNEL_ID:         ${{ secrets.DISCORD_HR_CHANNEL_ID }}
        # Location-specific channels
        DISCORD_REMOTE_USA_CHANNEL_ID: ${{ secrets.DISCORD_REMOTE_USA_CHANNEL_ID }}
        DISCORD_NY_CHANNEL_ID:         ${{ secrets.DISCORD_NY_CHANNEL_ID }}
        DISCORD_AUSTIN_CHANNEL_ID:     ${{ secrets.DISCORD_AUSTIN_CHANNEL_ID }}
        DISCORD_CHICAGO_CHANNEL_ID:    ${{ secrets.DISCORD_CHICAGO_CHANNEL_ID }}
        DISCORD_SEATTLE_CHANNEL_ID:    ${{ secrets.DISCORD_SEATTLE_CHANNEL_ID }}
        DISCORD_REDMOND_CHANNEL_ID:    ${{ secrets.DISCORD_REDMOND_CHANNEL_ID }}
        DISCORD_MV_CHANNEL_ID:         ${{ secrets.DISCORD_MV_CHANNEL_ID }}
        DISCORD_SF_CHANNEL_ID:         ${{ secrets.DISCORD_SF_CHANNEL_ID }}
        DISCORD_SUNNYVALE_CHANNEL_ID:  ${{ secrets.DISCORD_SUNNYVALE_CHANNEL_ID }}
        DISCORD_SAN_BRUNO_CHANNEL_ID:  ${{ secrets.DISCORD_SAN_BRUNO_CHANNEL_ID }}
        DISCORD_BOSTON_CHANNEL_ID:     ${{ secrets.DISCORD_BOSTON_CHANNEL_ID }}
        DISCORD_LA_CHANNEL_ID:         ${{ secrets.DISCORD_LA_CHANNEL_ID }}
        # Encrypted routing logs password
        LOG_ENCRYPT_PASSWORD:          ${{ secrets.LOG_ENCRYPT_PASSWORD }}

    - name: ðŸ” AFTER bot - Hash posted_jobs.json
      id: after-hash
      run: |
        echo "ðŸ“Š AFTER BOT EXECUTION:"
        echo "File size: $(stat -c'%s' .github/data/posted_jobs.json 2>/dev/null || stat -f'%z' .github/data/posted_jobs.json)"
        AFTER_HASH=$(sha256sum .github/data/posted_jobs.json 2>/dev/null | cut -d' ' -f1 || shasum -a 256 .github/data/posted_jobs.json | cut -d' ' -f1)
        echo "SHA256: $AFTER_HASH"
        echo "hash=$AFTER_HASH" >> $GITHUB_OUTPUT
        echo "Last 3 job IDs:"
        tail -3 .github/data/posted_jobs.json
        echo ""
        echo "Git diff check:"
        git diff .github/data/posted_jobs.json | head -20 || echo "No diff detected by git"

    - name: ðŸ” Verify database was updated
      run: |
        echo "ðŸ“Š VERIFYING DATABASE UPDATE..."
        echo ""

        BEFORE_HASH="${{ steps.before-hash.outputs.hash }}"
        AFTER_HASH="${{ steps.after-hash.outputs.hash }}"

        echo "Before hash: $BEFORE_HASH"
        echo "After hash:  $AFTER_HASH"
        echo ""

        # First, check posting results (graceful handling of partial failures)
        # Note: grep -c outputs "0" when no matches found, but exit code 1
        # Use || true to prevent pipeline failure, then default to 0 if empty
        SUCCESS_COUNT=$(grep -c "âœ… Created forum post" .github/logs/discord-bot.log 2>/dev/null || true)
        ERROR_COUNT=$(grep -c "âŒ Error posting job" .github/logs/discord-bot.log 2>/dev/null || true)
        CHANNEL_FULL_COUNT=$(grep -c "160006\|channel.*full\|max.*thread" .github/logs/discord-bot.log 2>/dev/null || true)

        # Default to 0 if empty (file missing) and trim whitespace
        SUCCESS_COUNT=$(echo "${SUCCESS_COUNT:-0}" | xargs)
        ERROR_COUNT=$(echo "${ERROR_COUNT:-0}" | xargs)
        CHANNEL_FULL_COUNT=$(echo "${CHANNEL_FULL_COUNT:-0}" | xargs)

        echo "ðŸ“Š Posting Results: $SUCCESS_COUNT succeeded, $ERROR_COUNT failed, $CHANNEL_FULL_COUNT channel-full"

        # If some jobs posted successfully, treat channel-full as warning not error
        if [ "$SUCCESS_COUNT" -gt 0 ]; then
          if [ "$CHANNEL_FULL_COUNT" -gt 0 ]; then
            echo "âš ï¸  Some channels were full (160006) but $SUCCESS_COUNT jobs posted successfully"
            echo "This is expected behavior - channels auto-archive after 3 days"
          fi
          # Continue to hash check (don't fail here)
        elif [ "$ERROR_COUNT" -gt 0 ]; then
          # No successes AND errors = critical failure
          echo "âŒâŒâŒ CRITICAL ERROR: All jobs failed to post to Discord! âŒâŒâŒ"
          echo ""
          echo "Bot encountered errors while posting jobs."
          echo "Check bot logs above for details."
          exit 1
        fi

        # Second, check if file unchanged (could be expected or error)
        if [ "$BEFORE_HASH" == "$AFTER_HASH" ]; then
          echo "âš ï¸  Database file unchanged - investigating reason..."
          echo ""

          # Check if all jobs were filtered (expected behavior)
          if grep -q "After blacklist filter: 0 jobs" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: All jobs filtered by blacklist (expected behavior)"
            echo ""
            echo "All new jobs matched blacklist criteria - no jobs posted."
            echo "This is normal and prevents posting unwanted duplicates."
            exit 0
          elif grep -q "No new jobs to post" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: No new jobs found (expected behavior)"
            echo ""
            echo "All jobs were already posted previously."
            echo "Duplicate detection working correctly."
            exit 0
          elif grep -q "â„¹ï¸ No new jobs to post" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: No new jobs to post (expected behavior)"
            echo ""
            echo "Either no new jobs found or all filtered as duplicates."
            exit 0
          else
            # File unchanged but we don't know why - this is suspicious!
            echo "âŒâŒâŒ CRITICAL ERROR: posted_jobs.json was NOT modified! âŒâŒâŒ"
            echo ""
            echo "Database unchanged but bot should have posted jobs."
            echo "This could indicate a save failure or other issue."
            echo ""
            echo "Check bot logs above for save errors."
            echo "This workflow will now fail to alert the team."
            exit 1
          fi
        else
          echo "âœ… SUCCESS: Database was updated correctly"
          echo ""
          echo "File hash changed, confirming bot saved posted job IDs."
          echo "Duplicate detection is working properly."
        fi

    - name: Upload private logs (collaborators only)
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: job-processing-logs-${{ github.run_number }}
        path: .github/logs/*.log
        retention-days: 90
        if-no-files-found: warn

    - name: Create obfuscated audit log
      if: always()
      run: node .github/scripts/create-audit-log.js

    - name: Check for changes
      id: verify-changed-files
      run: |
        echo "ðŸ“‹ Git status:"
        git status --porcelain
        echo ""
        echo "ðŸ“Š Posted jobs file info:"
        ls -lh .github/data/posted_jobs.json || echo "File not found!"
        echo "Last modified: $(stat -c '%y' .github/data/posted_jobs.json 2>/dev/null || stat -f '%Sm' .github/data/posted_jobs.json 2>/dev/null || echo 'unknown')"
        echo ""

        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
          echo "âœ… Found changes in files"
        else
          echo "changed=false" >> $GITHUB_OUTPUT
          echo "âš ï¸  No changes detected"
        fi

    - name: Commit and Push changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"

        # Function to commit and push with proper conflict resolution
        commit_and_push() {
          local max_attempts=5
          local delay=5

          for attempt in $(seq 1 $max_attempts); do
            echo "========================================="
            echo "Attempt $attempt of $max_attempts"
            echo "========================================="

            # STEP 1: Stash our changes (clean working directory)
            echo "ðŸ“¦ Stashing local changes..."
            git stash push -m "Auto-stash scraped jobs $(date +%s)" \
              .github/data/new_jobs.json \
              .github/data/posted_jobs.json \
              .github/data/seen_jobs.json \
              README.md || true

            # STEP 2: Pull latest remote changes with rebase
            echo "â¬‡ï¸  Pulling latest changes from remote..."
            if ! git pull --rebase origin master; then
              echo "âš ï¸  Rebase conflict detected, aborting rebase..."
              git rebase --abort || true

              # Fallback to regular merge
              git pull origin master --no-edit || {
                echo "âŒ Pull failed completely, resetting..."
                git reset --hard HEAD
                git pull origin master
              }
            fi

            # STEP 3: Re-apply our changes (our data is authoritative)
            echo "ðŸ“‚ Re-applying scraped job data..."
            if git stash list | grep -q "Auto-stash scraped jobs"; then
              if ! git stash pop; then
                echo "âš ï¸  Stash pop had conflicts, resolving..."

                # Take stashed version (latest scraped data) for all conflicts
                # --theirs = what's in the stash (NEW data after bot ran)
                # --ours = what's in working directory (OLD data before stash)
                git checkout --theirs .github/data/new_jobs.json 2>/dev/null || true
                git checkout --theirs .github/data/posted_jobs.json 2>/dev/null || true
                git checkout --theirs .github/data/seen_jobs.json 2>/dev/null || true
                git checkout --theirs README.md 2>/dev/null || true

                # Clear the stash
                git reset
                git stash drop || true
              fi
            else
              echo "â„¹ï¸  No stash found (likely no conflicts)"
            fi

            # STEP 4: Stage and commit
            git add .github/data/new_jobs.json \
                    .github/data/posted_jobs.json \
                    .github/data/seen_jobs.json \
                    .github/data/pending_posts.json \
                    .github/data/jobs-data-encrypted.json \
                    .github/audit/latest.md \
                    .github/audit/routing-encrypted.json \
                    README.md 2>/dev/null || true

            # Check if there are still changes to commit
            if git diff --staged --quiet; then
              echo "â„¹ï¸  No changes after merge, exiting successfully"
              exit 0
            fi

            # Get job count for commit message
            JOB_COUNT=$(grep -o "Active Positions\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
            COMPANY_COUNT=$(grep -o "Companies\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")

            COMMIT_MSG="Update jobs - $(date +'%Y-%m-%d %H:%M UTC')

        Found $JOB_COUNT positions from $COMPANY_COUNT companies
        Updated categories, locations, and experience levels"

            if ! git commit -m "$COMMIT_MSG"; then
              echo "âš ï¸  Commit failed, may already be committed"
            fi

            # STEP 5: Push with retry
            echo "â¬†ï¸  Pushing changes to remote..."
            if git push origin master; then
              echo "âœ… Successfully pushed changes!"
              exit 0
            else
              echo "âŒ Push failed (branch diverged again)"

              # Undo commit but keep changes staged for retry
              git reset --soft HEAD~1

              # Exponential backoff
              echo "â³ Waiting ${delay}s before retry..."
              sleep $delay
              delay=$((delay * 2))
            fi
          done

          echo "========================================="
          echo "âŒ Failed to push after $max_attempts attempts"
          echo "========================================="
          exit 1
        }

        # Execute the function
        commit_and_push

    - name: Create job summary
      run: |
        echo "## ðŸš€ Zapply Jobs Updated!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        if [ "${{ steps.verify-changed-files.outputs.changed }}" == "true" ]; then
          # Extract stats from README
          JOB_COUNT=$(grep -o "Active Positions\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          COMPANY_COUNT=$(grep -o "Companies\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          FAANG_COUNT=$(grep -o "FAANG+ Jobs\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")

          echo "âœ… **Successfully updated job board with fresh opportunities**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Today's Haul:" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŽ¯ **$JOB_COUNT total positions** from elite tech companies" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ¢ **$COMPANY_COUNT companies** tracked (FAANG, unicorns, startups)" >> $GITHUB_STEP_SUMMARY
          echo "- â­ **$FAANG_COUNT FAANG+ jobs** from top-tier companies" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ” Search Coverage:" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŒ **Multi-location search**: SF Bay Area, NYC, Seattle, Austin, Remote" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŽ“ **All experience levels**: Entry-level to Senior positions" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ’¼ **10+ role categories**: SWE, ML/AI, Data, Mobile, DevOps, Product, Design" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ† **Elite companies only**: FAANG, unicorns, top startups, gaming leaders" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸŽ¯ Quality Filters Applied:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ¨ Removed duplicates and spam postings" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ¢ Normalized company names and subsidiaries" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š Ranked by company tier (FAANG first)" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”— Verified direct application links" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ”„ Next update**: In ~15 minutes" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ“¥ Detailed logs**: Download artifacts (collaborators only)" >> $GITHUB_STEP_SUMMARY
        else
          echo "â„¹ï¸ **No new opportunities found - job board is current**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All tracked companies have been checked for new postings." >> $GITHUB_STEP_SUMMARY
          echo "The existing job listings are still fresh and active." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ”„ Next check**: In ~15 minutes" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ“¥ Detailed logs**: Download artifacts (collaborators only)" >> $GITHUB_STEP_SUMMARY
        fi
